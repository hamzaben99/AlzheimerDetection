{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nibabel.testing import data_path\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "\n",
    "path = str(Path().resolve())\n",
    "path = path + \"\\\\ADNI_PROCESSED\"\n",
    "\n",
    "def apply_mask(img_n_mmni, img_mask):\n",
    "    \"\"\"\n",
    "        Taking a n_mmni and apply the correspondant mask\n",
    "        param:\n",
    "            img_n_mmi   : image n_mmi\n",
    "            img_mask    : mask\n",
    "    \"\"\"\n",
    "    mmni_m = img_n_mmni.get_fdata()\n",
    "    mask_m = img_mask.get_fdata().astype(bool)\n",
    "    mask_bg = np.logical_not(mask_m)\n",
    "    mmni_m[mask_bg] = 0\n",
    "    return mmni_m\n",
    "\n",
    "def process_irm_data():\n",
    "    \"\"\"\n",
    "        Create a new directory and process all images from tha ADNI1 directory\n",
    "    \"\"\"\n",
    "    path = str(Path().resolve())\n",
    "    path_res = path + \"\\\\ADNI_PROCESSED\"\n",
    "    Path(path_res).mkdir(parents=True, exist_ok=True) # Create a directory for data processed\n",
    "    path = path + \"\\\\ADNI1\"\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.startswith(\"n_mmni\"):\n",
    "            n_mmni_filename = os.path.join(path, filename)\n",
    "            mask_filename = os.path.join(path, \"mask_\" + filename)\n",
    "            img_n_mmni = nib.load(n_mmni_filename)\n",
    "            img_mask = nib.load(mask_filename)\n",
    "            n_mmni_mask = apply_mask(img_n_mmni, img_mask)\n",
    "            img = nib.Nifti1Image(n_mmni_mask, np.eye(4))\n",
    "            nib.save(img, os.path.join(path_res, filename))\n",
    "\n",
    "# process_irm_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed_data(path):\n",
    "    \"\"\"\n",
    "        load all n_mmni found in the path\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        print(\"Can't found directory: \" + path)\n",
    "    else:\n",
    "        list_x = []\n",
    "        for filename in os.listdir(path):\n",
    "            n_mmni_filename = os.path.join(path, filename)\n",
    "            img_n_mmni = nib.load(n_mmni_filename)\n",
    "            mmni_matrix = img_n_mmni.get_fdata()\n",
    "            list_x.append((filename, mmni_matrix))\n",
    "        return list_x\n",
    "\n",
    "# Not tested yet; crashed last time\n",
    "# path = str(Path().resolve())\n",
    "# path_to_data_proc = path + \"\\\\ADNI_PROCESSED\"\n",
    "# X = load_processed_data(path_to_data_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_2D_i(img_n_mmni, axe, idx):\n",
    "    \"\"\"\n",
    "        Function that returns a 2D cut from the \"img\" in the index \"idx\", along the axe given in parameter\n",
    "    \"\"\"\n",
    "    axe_dim = {\"x\": img_n_mmni.shape[0], \"y\": img_n_mmni.shape[1], \"z\":img_n_mmni.shape[2]}\n",
    "    if axe_dim[axe] <= idx or idx < 0:\n",
    "        print(\"Invalid value for index must be between 0 and \" , axe_dim[axe])\n",
    "        return\n",
    "    if axe == \"x\":\n",
    "        cropped_img = img_n_mmni.slicer[idx:idx+1, ...]\n",
    "    elif axe == \"y\":\n",
    "        cropped_img = img_n_mmni.slicer[:, idx:idx+1,:]\n",
    "    elif axe == \"z\":\n",
    "        cropped_img = img_n_mmni.slicer[..., idx:idx+1]\n",
    "    else:\n",
    "        print(\"Choose a valid value for axe: x, y or z\")\n",
    "    return cropped_img\n",
    "\n",
    "def patch_3D(img_n_mmni, axe, idx_start, idx_end):\n",
    "    \"\"\"\n",
    "        Function that returns a 3D patch from the \"img\" along the axe given in parameter, from the idx_start to idx_end\n",
    "    \"\"\"\n",
    "    axe_dim = {\"x\": img_n_mmni.shape[0], \"y\": img_n_mmni.shape[1], \"z\":img_n_mmni.shape[2]}\n",
    "    if axe_dim[axe] <= idx_start or idx_start < 0 or axe_dim[axe] <= idx_end or idx_end < 0 or idx_start >= idx_end:\n",
    "        print(\"Invalid value for index must, values must be between 0 and \" , axe_dim[axe], \"and idx_start must be greater than idx_end\")\n",
    "        return\n",
    "    if axe == \"x\":\n",
    "        cropped_img = img_n_mmni.slicer[idx_start:idx_end, ...]\n",
    "    elif axe == \"y\":\n",
    "        cropped_img = img_n_mmni.slicer[:, idx_start:idx_end,:]\n",
    "    elif axe == \"z\":\n",
    "        cropped_img = img_n_mmni.slicer[..., idx_start:idx_end]\n",
    "    else:\n",
    "        print(\"Choose a valid value for axe: x, y or z\")\n",
    "    return cropped_img\n",
    "\n",
    "# To test thid function\n",
    "n_mmni_filename = os.path.join(path, \"n_mmni_fADNI_002_S_0295_1.5T_t1w.nii.gz\")\n",
    "img_n_mmni = nib.load(n_mmni_filename)\n",
    "crop_img = patch_3D(img_n_mmni, \"z\", 90, 120)\n",
    "IM_HEIGHT = crop_img.shape[0]\n",
    "IM_WIDTH = crop_img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_X_data(path):\n",
    "    if not os.path.isdir(path):\n",
    "        print(\"Can't found directory: \" + path)\n",
    "    else:\n",
    "        list_x = []\n",
    "        for filename in os.listdir(path):\n",
    "            n_mmni_filename = os.path.join(path, filename)\n",
    "            img_n_mmni = nib.load(n_mmni_filename)\n",
    "            # Customize your choice: taking a 2D cuts or 3D patches\n",
    "            cropped_img = cut_2D_i(img_n_mmni, \"z\", 90)\n",
    "            cropped_n_mmni_matrix = cropped_img.get_fdata()\n",
    "            list_x.append((filename, cropped_n_mmni_matrix))\n",
    "        return list_x\n",
    "\n",
    "X_data = load_X_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Appolyon\\AppData\\Local\\Temp/ipykernel_23628/2551298555.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Group'] = data_cat_encoded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooster ID</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>002_S_0295</th>\n",
       "      <td>295</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_S_0413</th>\n",
       "      <td>413</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_S_0559</th>\n",
       "      <td>559</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_S_0619</th>\n",
       "      <td>619</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_S_0685</th>\n",
       "      <td>685</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_S_0816</th>\n",
       "      <td>816</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_S_0938</th>\n",
       "      <td>938</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_S_0955</th>\n",
       "      <td>955</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_S_1018</th>\n",
       "      <td>1018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_S_1261</th>\n",
       "      <td>1261</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rooster ID  Group\n",
       "Subject ID                   \n",
       "002_S_0295         295    1.0\n",
       "002_S_0413         413    1.0\n",
       "002_S_0559         559    1.0\n",
       "002_S_0619         619    0.0\n",
       "002_S_0685         685    1.0\n",
       "002_S_0816         816    0.0\n",
       "002_S_0938         938    0.0\n",
       "002_S_0955         955    0.0\n",
       "002_S_1018        1018    0.0\n",
       "002_S_1261        1261    1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path, names= ['Subject ID', 'Rooster ID', 'Age', 'Sexe', 'Group', 'Conversion', 'MMSE', 'RAVLT', 'FAQ', 'CDR-SB', 'ADAS11'], usecols = ['Subject ID', 'Rooster ID', 'Group'])\n",
    "    data.index = data['Subject ID']\n",
    "    data = data.drop(['Subject ID'], axis=1)\n",
    "    return data\n",
    "\n",
    "path = str(Path().resolve())\n",
    "path = path + \"/ADNI1/list_standardized_tongtong_2017.csv\"\n",
    "y_data = load_data(path)\n",
    "\n",
    "def process_data(data):\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    data = data[(data.Group == 'CN') | (data.Group == 'AD')]\n",
    "    data_cat = data[['Group']] \n",
    "    data_cat_encoded = ordinal_encoder.fit_transform(data_cat)\n",
    "    data['Group'] = data_cat_encoded\n",
    "    return data\n",
    "\n",
    "y_data = process_data(y_data)\n",
    "y_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols = ['Subject ID', 'Rooster ID', 'Group']\n",
    "def prepare_X_of_Y(Y_data):\n",
    "    X_data = [] #np.zeros((len(Y_data), IM_HEIGHT, IM_WIDTH, 1), dtype=np.float32)\n",
    "    path = str(Path().resolve())\n",
    "    path += \"\\\\ADNI_PROCESSED\"\n",
    "    for index, row in Y_data.iterrows():\n",
    "        file = path + '\\\\n_mmni_fADNI_' + index + '_1.5T_t1w.nii.gz'\n",
    "        if os.path.isfile(file):\n",
    "            img_n_mmni = nib.load(file)\n",
    "            crop_img = cut_2D_i(img_n_mmni, \"z\", 90)\n",
    "            X_data.append(crop_img.get_fdata())\n",
    "        else:\n",
    "            Y_data.drop(index, inplace=True)\n",
    "    return np.array(X_data), Y_data\n",
    "\n",
    "X_data, Y_data = prepare_X_of_Y(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Neural Network\n",
    "\n",
    "Creation of two U-Net models:\n",
    "* One for 2D inputs, in case we slice the input into 2D images.\n",
    "* The other for 3D inputs, in case we use 3D blocs of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Cropping2D, Conv3D, MaxPooling3D, UpSampling3D, Cropping3D, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_Unet_model2D(input_size, depth=5, padding='valid'):\n",
    "    inputs = Input(shape=input_size)\n",
    "    x = inputs\n",
    "    num_filters = 64\n",
    "    encode_layers_list = []\n",
    "    for i in range(depth):\n",
    "        x = Conv2D(filters=num_filters, kernel_size=(3,3), padding=padding, activation='relu')(x)\n",
    "        x = Conv2D(filters=num_filters, kernel_size=(3,3), padding=padding, activation='relu')(x)\n",
    "        if i != depth - 1:\n",
    "            encode_layers_list.append(x)\n",
    "            x = MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "            num_filters *= 2\n",
    "    \n",
    "    for i in range(depth - 1):\n",
    "        x = UpSampling2D()(x)\n",
    "        x = Conv2D(filters=num_filters, kernel_size=(2,2), padding='same', activation='relu')(x)\n",
    "        #cropping\n",
    "        encoder_shape = encode_layers_list[depth - 2 - i].shape\n",
    "        decoder_shape = x.shape\n",
    "        shape_diff = (encoder_shape[1] - decoder_shape[1], encoder_shape[2] - decoder_shape[2])\n",
    "        xshape_diff = shape_diff[0] // 2\n",
    "        yshape_diff = shape_diff[1] // 2\n",
    "        if shape_diff[0] % 2 != 0:\n",
    "            xshape_diff = (shape_diff[0] // 2, shape_diff[0] // 2 + 1)\n",
    "        if shape_diff[1] % 2 != 0:\n",
    "            yshape_diff = (shape_diff[1] // 2, shape_diff[1] // 2 + 1)\n",
    "        croped_layer = Cropping2D(cropping=(xshape_diff, yshape_diff))(encode_layers_list[depth - 2 - i])\n",
    "        \n",
    "        x = concatenate([croped_layer, x])\n",
    "        num_filters /= 2\n",
    "        x = Conv2D(filters=num_filters, kernel_size=(3,3), padding=padding, activation='relu')(x)\n",
    "        x = Conv2D(filters=num_filters, kernel_size=(3,3), padding=padding, activation='relu')(x)\n",
    "\n",
    "    outputs = Conv2D(filters=2, padding=padding, kernel_size=(1,1))(x)\n",
    "        \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "def create_Unet_model3D(input_size, depth=5, padding='valid'):\n",
    "    inputs = Input(shape=input_size)\n",
    "    x = inputs\n",
    "    num_filters = 64\n",
    "    encode_layers_list = []\n",
    "    for i in range(depth):\n",
    "        x = Conv3D(filters=num_filters, kernel_size=(3,3,3), padding=padding, activation='relu')(x)\n",
    "        x = Conv3D(filters=num_filters, kernel_size=(3,3,3), padding=padding, activation='relu')(x)\n",
    "        if i != depth - 1:\n",
    "            encode_layers_list.append(x)\n",
    "            x = MaxPooling3D(pool_size=(2,2,2), strides=2)(x)\n",
    "            num_filters *= 2\n",
    "    \n",
    "\n",
    "    for i in range(depth - 1):\n",
    "        x = UpSampling3D()(x)\n",
    "        x = Conv3D(filters=num_filters, kernel_size=(2,2,2), activation='relu', padding='same')(x)\n",
    "        #cropping\n",
    "        encoder_shape = encode_layers_list[depth - 2 - i].shape\n",
    "        decoder_shape = x.shape\n",
    "        shape_diff = (encoder_shape[1] - decoder_shape[1], encoder_shape[2] - decoder_shape[2], encoder_shape[3] - decoder_shape[3])\n",
    "        xshape_diff = shape_diff[0] // 2\n",
    "        yshape_diff = shape_diff[1] // 2\n",
    "        zshape_diff = shape_diff[2] // 2\n",
    "        if shape_diff[0] % 2 != 0:\n",
    "            xshape_diff = (shape_diff[0] // 2, shape_diff[0] // 2 + 1)\n",
    "        if shape_diff[1] % 2 != 0:\n",
    "            yshape_diff = (shape_diff[1] // 2, shape_diff[1] // 2 + 1)\n",
    "        if shape_diff[2] % 2 != 0:\n",
    "            zshape_diff = (shape_diff[2] // 2, shape_diff[2] // 2 + 1)\n",
    "        croped_layer = Cropping3D(cropping=(xshape_diff, yshape_diff, zshape_diff))(encode_layers_list[depth - 2 - i])\n",
    "\n",
    "        x = concatenate([croped_layer, x])\n",
    "        num_filters /= 2\n",
    "        x = Conv3D(filters=num_filters, kernel_size=(3,3,3), padding=padding, activation='relu')(x)\n",
    "        x = Conv3D(filters=num_filters, kernel_size=(3,3,3), padding=padding, activation='relu')(x)\n",
    "\n",
    "    outputs = Conv3D(filters=2, kernel_size=(1,1,1))(x)\n",
    "        \n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 181, 217, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 179, 215, 64  640         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 177, 213, 64  36928       ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 88, 106, 64)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 86, 104, 128  73856       ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 84, 102, 128  147584      ['conv2d_2[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 42, 51, 128)  0          ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 40, 49, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 38, 47, 256)  590080      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 19, 23, 256)  0          ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 17, 21, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 15, 19, 512)  2359808     ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 30, 38, 512)  0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " cropping2d (Cropping2D)        (None, 30, 38, 256)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 30, 38, 512)  1049088     ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 30, 38, 768)  0           ['cropping2d[0][0]',             \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 28, 36, 256)  1769728     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 26, 34, 256)  590080      ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 52, 68, 256)  0          ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " cropping2d_1 (Cropping2D)      (None, 52, 68, 128)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 52, 68, 256)  262400      ['up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 52, 68, 384)  0           ['cropping2d_1[0][0]',           \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 50, 66, 128)  442496      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 48, 64, 128)  147584      ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 96, 128, 128  0          ['conv2d_13[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " cropping2d_2 (Cropping2D)      (None, 96, 128, 64)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 96, 128, 128  65664       ['up_sampling2d_2[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 96, 128, 192  0           ['cropping2d_2[0][0]',           \n",
      "                                )                                 'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 94, 126, 64)  110656      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 92, 124, 64)  36928       ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 92, 124, 2)   130         ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,158,978\n",
      "Trainable params: 9,158,978\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2d = create_Unet_model2D(X_data[0].shape, depth=4)\n",
    "model_2d.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_2d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
