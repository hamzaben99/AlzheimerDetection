{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nibabel.testing import data_path\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "\n",
    "path = str(Path().resolve())\n",
    "path = path + \"\\\\ADNI_PROCESSED\"\n",
    "\n",
    "def apply_mask(img_n_mmni, img_mask):\n",
    "    \"\"\"\n",
    "        Taking a n_mmni and apply the correspondant mask\n",
    "        param:\n",
    "            img_n_mmi   : image n_mmi\n",
    "            img_mask    : mask\n",
    "    \"\"\"\n",
    "    mmni_m = img_n_mmni.get_fdata()\n",
    "    mask_m = img_mask.get_fdata().astype(bool)\n",
    "    mask_bg = np.logical_not(mask_m)\n",
    "    mmni_m[mask_bg] = 0\n",
    "    return mmni_m\n",
    "\n",
    "def process_irm_data():\n",
    "    \"\"\"\n",
    "        Create a new directory and process all images from tha ADNI1 directory\n",
    "    \"\"\"\n",
    "    path = str(Path().resolve())\n",
    "    path_res = path + \"\\\\ADNI_PROCESSED\"\n",
    "    Path(path_res).mkdir(parents=True, exist_ok=True) # Create a directory for data processed\n",
    "    path = path + \"\\\\ADNI1\"\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.startswith(\"n_mmni\"):\n",
    "            n_mmni_filename = os.path.join(path, filename)\n",
    "            mask_filename = os.path.join(path, \"mask_\" + filename)\n",
    "            img_n_mmni = nib.load(n_mmni_filename)\n",
    "            img_mask = nib.load(mask_filename)\n",
    "            n_mmni_mask = apply_mask(img_n_mmni, img_mask)\n",
    "            img = nib.Nifti1Image(n_mmni_mask, np.eye(4))\n",
    "            nib.save(img, os.path.join(path_res, filename))\n",
    "\n",
    "process_irm_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed_data(path):\n",
    "    \"\"\"\n",
    "        load all n_mmni found in the path\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        print(\"Can't found directory: \" + path)\n",
    "    else:\n",
    "        list_x = []\n",
    "        for filename in os.listdir(path):\n",
    "            n_mmni_filename = os.path.join(path, filename)\n",
    "            img_n_mmni = nib.load(n_mmni_filename)\n",
    "            mmni_matrix = img_n_mmni.get_fdata()\n",
    "            list_x.append((filename, mmni_matrix))\n",
    "        return list_x\n",
    "\n",
    "# Not tested yet; crashed last time\n",
    "# path = str(Path().resolve())\n",
    "# path_to_data_proc = path + \"\\\\ADNI_PROCESSED\"\n",
    "# X = load_processed_data(path_to_data_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_2D_i(img_n_mmni, axe, idx):\n",
    "    \"\"\"\n",
    "        Function that returns a 2D cut from the \"img\" in the index \"idx\", along the axe given in parameter\n",
    "    \"\"\"\n",
    "    axe_dim = {\"x\": img_n_mmni.shape[0], \"y\": img_n_mmni.shape[1], \"z\":img_n_mmni.shape[2]}\n",
    "    if axe_dim[axe] <= idx or idx < 0:\n",
    "        print(\"Invalid value for index must be between 0 and \" , axe_dim[axe])\n",
    "        return\n",
    "    if axe == \"x\":\n",
    "        cropped_img = img_n_mmni.slicer[idx:idx+1, ...]\n",
    "    elif axe == \"y\":\n",
    "        cropped_img = img_n_mmni.slicer[:, idx:idx+1,:]\n",
    "    elif axe == \"z\":\n",
    "        cropped_img = img_n_mmni.slicer[..., idx:idx+1]\n",
    "    else:\n",
    "        print(\"Choose a valid value for axe: x, y or z\")\n",
    "    return cropped_img\n",
    "\n",
    "def patch_3D(img_n_mmni, axe, idx_start, idx_end):\n",
    "    \"\"\"\n",
    "        Function that returns a 3D patch from the \"img\" along the axe given in parameter, from the idx_start to idx_end\n",
    "    \"\"\"\n",
    "    axe_dim = {\"x\": img_n_mmni.shape[0], \"y\": img_n_mmni.shape[1], \"z\":img_n_mmni.shape[2]}\n",
    "    if axe_dim[axe] <= idx_start or idx_start < 0 or axe_dim[axe] <= idx_end or idx_end < 0 or idx_start >= idx_end:\n",
    "        print(\"Invalid value for index must, values must be between 0 and \" , axe_dim[axe], \"and idx_start must be greater than idx_end\")\n",
    "        return\n",
    "    if axe == \"x\":\n",
    "        cropped_img = img_n_mmni.slicer[idx_start:idx_end, ...]\n",
    "    elif axe == \"y\":\n",
    "        cropped_img = img_n_mmni.slicer[:, idx_start:idx_end,:]\n",
    "    elif axe == \"z\":\n",
    "        cropped_img = img_n_mmni.slicer[..., idx_start:idx_end]\n",
    "    else:\n",
    "        print(\"Choose a valid value for axe: x, y or z\")\n",
    "    return cropped_img\n",
    "\n",
    "# To test thid function\n",
    "n_mmni_filename = os.path.join(path, \"n_mmni_fADNI_002_S_0295_1.5T_t1w.nii.gz\")\n",
    "img_n_mmni = nib.load(n_mmni_filename)\n",
    "crop_img = cut_2D_i(img_n_mmni, \"z\", 90)\n",
    "crop_img.shape\n",
    "nib.save(crop_img, 'test_image.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_X_data(path):\n",
    "    if not os.path.isdir(path):\n",
    "        print(\"Can't found directory: \" + path)\n",
    "    else:\n",
    "        list_x = []\n",
    "        for filename in os.listdir(path):\n",
    "            n_mmni_filename = os.path.join(path, filename)\n",
    "            img_n_mmni = nib.load(n_mmni_filename)\n",
    "            # Customize your choice: taking a 2D cuts or 3D patches\n",
    "            cropped_img = cut_2D_i(img_n_mmni, \"z\", 90)\n",
    "            cropped_n_mmni_matrix = cropped_img.get_fdata()\n",
    "            list_x.append((filename, cropped_n_mmni_matrix))\n",
    "        return list_x\n",
    "\n",
    "X_data = load_X_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Neural Network\n",
    "\n",
    "Creation of two U-Net models:\n",
    "* One for 2D inputs, in case we slice the input into 2D images.\n",
    "* The other for 3D inputs, in case we use 3D blocs of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv3D, MaxPooling3D, UpSampling3D , Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_Unet_model2D(inputs, input_size, depth=5):\n",
    "    x = Input(shape=input_size)\n",
    "    num_filters = 64\n",
    "    for i in range(depth):\n",
    "        x = Conv2D(filters=num_filters, kernel_size=(3,3), activation='relu')(x)\n",
    "        x = Conv2D(filters=num_filters, kernel_size=(3,3), activation='relu')(x)\n",
    "        if i != depth - 1:\n",
    "            x = MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "        num_filters *= 2\n",
    "    \n",
    "\n",
    "    for i in range(depth):\n",
    "        if i != depth - 1:\n",
    "            x = UpSampling2D()(x)\n",
    "            x = Conv2D(filters=num_filters, kernel_size=(2,2))(x)\n",
    "        num_filters /= 2\n",
    "        x = Conv2D(filters=num_filters, kernel_size=(3,3), activation='relu')(x)\n",
    "        x = Conv2D(filters=num_filters, kernel_size=(3,3), activation='relu')(x)\n",
    "\n",
    "    outputs = Conv2D(filters=2, kernel_size=(1,1))\n",
    "        \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "def create_Unet_model3D(inputs, input_size, depth=5):\n",
    "    x = Input(shape=input_size)\n",
    "    num_filters = 64\n",
    "    for i in range(depth):\n",
    "        x = Conv3D(filters=num_filters, kernel_size=(3,3), activation='relu')(x)\n",
    "        x = Conv3D(filters=num_filters, kernel_size=(3,3), activation='relu')(x)\n",
    "        if i != depth - 1:\n",
    "            x = MaxPooling3D(pool_size=(2,2), strides=2)(x)\n",
    "        num_filters *= 2\n",
    "    \n",
    "\n",
    "    for i in range(depth):\n",
    "        if i != depth - 1:\n",
    "            x = UpSampling3D()(x)\n",
    "            x = Conv3D(filters=num_filters, kernel_size=(2,2))(x)\n",
    "        num_filters /= 2\n",
    "        x = Conv3D(filters=num_filters, kernel_size=(3,3), activation='relu')(x)\n",
    "        x = Conv3D(filters=num_filters, kernel_size=(3,3), activation='relu')(x)\n",
    "\n",
    "    outputs = Conv3D(filters=2, kernel_size=(1,1))\n",
    "        \n",
    "    return Model(inputs, outputs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5e12deb8414e12dfee55387d22d3cd622d9b9129110fd76de44846bbfabb930"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
